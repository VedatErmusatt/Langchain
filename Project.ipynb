{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "638dc941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f392700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e61a8eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dc5bd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://blog.langchain.dev/langgraph-platform-ga/\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e97a147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78793ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b291abdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter =  RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0cb08f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7b3c567",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c00d9fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4222156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        (\"user\", \"Given the above conversation, generate a search query to look uo up in to get information relevant to the conversation.\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be70159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "\n",
    "retriever_chain = create_history_aware_retriever(\n",
    "    model, retriever, prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45f1351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = [\n",
    "    HumanMessage(\n",
    "        content=\"Can I use LangGraph for agent runtimes?\"\n",
    "    ),\n",
    "    AIMessage(content=\"Yes!\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fe18176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='8dbc9c8f-e387-4e91-ad54-4bcaf5521aeb', metadata={'source': 'https://blog.langchain.dev/langgraph-platform-ga/', 'title': 'LangGraph Platform is now Generally Available: Deploy & manage long-running, stateful Agents', 'description': 'LangGraph Platform, our infrastructure for deploying and managing agents at scale, is now generally available. Learn how to deploy', 'language': 'en'}, page_content='management console makes it easier to enforce consistency, monitor behavior, and ship updates safely — all without needing to re-deploy or touch code every time. You can:Discover available agents in the agent registryCreate different versions of your agent (“assistants”) in LangGraph platform, allowing you to reuse common agent architectures\\xa0Leverage other agents as “Remote Graphs”, allowing you to create multi agent architectures that run in a distributed mannerFor companies like Qualtrics, centralizing agent management with LangGraph Platform has been critical to driving efficiency:\\xa0\"The future of agentic AI is multi-vendor and AI agents must be built in an ecosystem. By using LangGraph Platform to build and manage our AI agents - Experience Agents - Qualtrics is able to design, deploy, and manage complex generative AI agent workflows with efficiency, speed, and scale.\" – Phil McKennan, VP of Strategy and Partnerships at QualtricsTry LangGraph Platform todayLangGraph Platform reduces time to production and enables better application experiences with a runtime that suits the workload and improves DevEx with well crafted APIs, built-in memory, and a Studio development environment. Today, LangGraph Platform is generally available.\\xa0To get started, choose the deployment option that fits your team’s needs:\\xa0Cloud (SaaS): Fastest way to get started, fully managed and easy deployment from within LangSmith. Available on our Plus plan and Enterprise plan.\\xa0To get started, read the docs (Plus plan) or\\xa0contact sales (Enterprise).Hybrid: SaaS control plane with self-hosted data plane — ideal for teams with sensitive data but still want more of a managed service. Available only on the Enterprise plan.\\xa0To get started, contact salesFully Self-Hosted: Run the entire platform within your own infrastructure. No data leaves your VPC. Available on the Enterprise plan. To get started, contact sales.If you want to try out a basic version of our LangGraph server in your environment, you can also self-host on our Developer plan and get up to 100k nodes executed per month for free – great to give you exposure to LangGraph Platform and run hobbyist projects on your infra. To get started on the Developer tier, read the docs.Learn more about deployment options here and view pricing details.\\xa0LangGraph Platform is the easiest way to develop, deploy, and manage long-running, stateful agents. It can be used independently from LangChain’s other products – LangChain (integrations), LangGraph (agent orchestration), and LangSmith (Evals and Observability), or stack together to provide an easy transition from the build phase to production.To learn more, visit the LangGraph Platform webpage. We can’t wait to see how far you can run with your agents.'),\n",
       " Document(id='6745b132-1f51-42d9-905b-ca255f39aa66', metadata={'source': 'https://blog.langchain.dev/langgraph-platform-ga/', 'title': 'LangGraph Platform is now Generally Available: Deploy & manage long-running, stateful Agents', 'description': 'LangGraph Platform, our infrastructure for deploying and managing agents at scale, is now generally available. Learn how to deploy', 'language': 'en'}, page_content='LangGraph Platform is now Generally Available: Deploy & manage long-running, stateful Agents\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCase Studies\\n\\n\\n\\n\\nIn the Loop\\n\\n\\n\\n\\nLangChain\\n\\n\\n\\n\\nDocs\\n\\n\\n\\n\\nChangelog\\n\\n\\n\\n\\n\\nSign in\\nSubscribe\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLangGraph Platform is now Generally Available: Deploy & manage long-running, stateful Agents\\nLangGraph Platform, our infrastructure for deploying and managing agents at scale, is now generally available. Learn how to deploy\\n\\n4 min read\\nMay 14, 2025'),\n",
       " Document(id='1d592445-3560-4033-8ccb-301b4753e5cb', metadata={'source': 'https://blog.langchain.dev/langgraph-platform-ga/', 'title': 'LangGraph Platform is now Generally Available: Deploy & manage long-running, stateful Agents', 'description': 'LangGraph Platform, our infrastructure for deploying and managing agents at scale, is now generally available. Learn how to deploy', 'language': 'en'}, page_content=\"Today we’re excited to announce the general availability of LangGraph Platform — our purpose-built infrastructure and management layer for deploying and scaling long-running, stateful agents. Since our beta last June, nearly 400 companies have used LangGraph Platform to deploy their agents into production.\\xa0Agent deployment is the next hard hurdle for shipping reliable agents, and LangGraph Platform dramatically lowers this barrier with:1-click deployment to go live in minutes,\\xa030 API endpoints for designing custom user experiences that fit any interaction patternHorizontal scaling to handle bursty, long-running trafficA persistence layer to support memory, conversational history, and async collaboration with human-in-the-loop or multi-agent workflowsNative LangGraph Studio, the agent IDE, for easy debugging, visibility, and iterationRead on to learn more about what LangGraph Platform offers and which deployment option is right for you. If you're more of a visual learner, you can check out our video walkthrough here.The challenges of agent infrastructure – and how LangGraph Platform can helpOur team has the privilege of working with many of the most exciting companies building agents –\\xa0 such as Klarna, Lovable, Replit, Clay, LinkedIn. Through close collaboration, we’ve come to believe that the challenges of running agents, at scale, in production are often unique relative to traditional apps:Many agents are long running. Like we’ve seen with deep research agents, agents that run in the background on a schedule or in response to environment triggers can take a long time to return a final output. These workflows can be prone to failures mid-task, so they need durable infrastructure to ensure task completion.Many agents rely on async collaboration. Agents need to act on inputs from unpredictable events, whether collaborating with a human to steer / approve an action or waiting on another agent. For example – will the human reply immediately, tomorrow, or not at all? Good infrastructure accounts for this chaos and preserves state throughout.Bursty. While not totally unique to agents, horizontally scaling infra to handle traffic spikes is challenging –\\xa0 especially for tasks that run daily or on schedules.\\xa0We want engineers to obsess over building the best agent architecture – not worry about infra. LangGraph Platform’s server suits these kinds of workloads at scale. Developers can just 1-click deploy their apps directly in the management console to get started.1-click deploy with our native GitHub integration —\\xa0just select a repo, and ship! Accelerate agent development with visual workflowsBuilding great agents requires fast feedback loops. LangGraph Studio (included as part of LangGraph Platform) helps developers visualize and debug agent workflows in real time, with detailed visibility into agent trajectories and support for branching logic and retries.\\xa0You can also test edge cases, inspect memory/state at each step, and quickly pinpoint where things go wrong. Instead of retrying things from scratch, built-in checkpointing and memory modules in LangGraph Platform make it easy to rewind, edit, and rerun failure points without frustration.Whether you’re using our pre-built agent templates for common agent workflows, or building from scratch, LangGraph Platform lets you scaffold your agentic apps quickly – going from an idea to production in hours.\\xa0Centralize agent management across your orgAs agents get adopted across teams, managing them becomes a team sport. LangGraph Platform gives organizations a unified view of every agent in development or production — helping fellow team members iterate and scale across use cases. The enterprise tier also supports RBAC and workspaces, so that you can control access and sharing.The LangGraph Platform management console makes it easier to enforce consistency, monitor behavior, and ship updates safely — all without needing to re-deploy or touch code every time. You can:Discover available agents\"),\n",
       " Document(id='cb8460a1-efe3-424f-885a-f14733ef914e', metadata={'source': 'https://blog.langchain.dev/langgraph-platform-ga/', 'title': 'LangGraph Platform is now Generally Available: Deploy & manage long-running, stateful Agents', 'description': 'LangGraph Platform, our infrastructure for deploying and managing agents at scale, is now generally available. Learn how to deploy', 'language': 'en'}, page_content='Join our newsletter\\nUpdates from the LangChain team and community\\n\\n\\nEnter your email\\n\\nSubscribe\\n\\nProcessing your application...\\nSuccess! Please check your inbox and click the link to confirm your subscription.\\nSorry, something went wrong. Please try again.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSign up\\n\\n\\n\\n\\n\\n            © LangChain Blog 2025')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_chain.invoke(\n",
    "    {\n",
    "        \"chat_history\": chat_history,\n",
    "        \"input\": \"Tell me how\",\n",
    "    }\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cecf1550",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Answer the user's questions based on the below context. \\n\\n{context}\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d403f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bu metod dokümanları modele geçirebilmek için bir chain oluşturmak için\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain \n",
    "\n",
    "documents_chain = create_stuff_documents_chain(model, prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "249d46e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever_chain = create_retrieval_chain(retriever_chain, documents_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef5ddc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Conversational RAG\n",
    "chat_history = [\n",
    "    HumanMessage(content=\"Can I use LangGraph for agent runtimes?\"),\n",
    "    AIMessage(content=\"Yes!\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8567c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = retriever_chain.invoke(\n",
    "    {\n",
    "        \"chat_history\": chat_history,\n",
    "        \"input\": \"Tell me how\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5e5046e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chat_history': [HumanMessage(content='Can I use LangGraph for agent runtimes?', additional_kwargs={}, response_metadata={}), AIMessage(content='Yes!', additional_kwargs={}, response_metadata={})], 'input': 'Tell me how', 'context': [Document(id='8dbc9c8f-e387-4e91-ad54-4bcaf5521aeb', metadata={'source': 'https://blog.langchain.dev/langgraph-platform-ga/', 'title': 'LangGraph Platform is now Generally Available: Deploy & manage long-running, stateful Agents', 'description': 'LangGraph Platform, our infrastructure for deploying and managing agents at scale, is now generally available. Learn how to deploy', 'language': 'en'}, page_content='management console makes it easier to enforce consistency, monitor behavior, and ship updates safely — all without needing to re-deploy or touch code every time. You can:Discover available agents in the agent registryCreate different versions of your agent (“assistants”) in LangGraph platform, allowing you to reuse common agent architectures\\xa0Leverage other agents as “Remote Graphs”, allowing you to create multi agent architectures that run in a distributed mannerFor companies like Qualtrics, centralizing agent management with LangGraph Platform has been critical to driving efficiency:\\xa0\"The future of agentic AI is multi-vendor and AI agents must be built in an ecosystem. By using LangGraph Platform to build and manage our AI agents - Experience Agents - Qualtrics is able to design, deploy, and manage complex generative AI agent workflows with efficiency, speed, and scale.\" – Phil McKennan, VP of Strategy and Partnerships at QualtricsTry LangGraph Platform todayLangGraph Platform reduces time to production and enables better application experiences with a runtime that suits the workload and improves DevEx with well crafted APIs, built-in memory, and a Studio development environment. Today, LangGraph Platform is generally available.\\xa0To get started, choose the deployment option that fits your team’s needs:\\xa0Cloud (SaaS): Fastest way to get started, fully managed and easy deployment from within LangSmith. Available on our Plus plan and Enterprise plan.\\xa0To get started, read the docs (Plus plan) or\\xa0contact sales (Enterprise).Hybrid: SaaS control plane with self-hosted data plane — ideal for teams with sensitive data but still want more of a managed service. Available only on the Enterprise plan.\\xa0To get started, contact salesFully Self-Hosted: Run the entire platform within your own infrastructure. No data leaves your VPC. Available on the Enterprise plan. To get started, contact sales.If you want to try out a basic version of our LangGraph server in your environment, you can also self-host on our Developer plan and get up to 100k nodes executed per month for free – great to give you exposure to LangGraph Platform and run hobbyist projects on your infra. To get started on the Developer tier, read the docs.Learn more about deployment options here and view pricing details.\\xa0LangGraph Platform is the easiest way to develop, deploy, and manage long-running, stateful agents. It can be used independently from LangChain’s other products – LangChain (integrations), LangGraph (agent orchestration), and LangSmith (Evals and Observability), or stack together to provide an easy transition from the build phase to production.To learn more, visit the LangGraph Platform webpage. We can’t wait to see how far you can run with your agents.'), Document(id='6745b132-1f51-42d9-905b-ca255f39aa66', metadata={'source': 'https://blog.langchain.dev/langgraph-platform-ga/', 'title': 'LangGraph Platform is now Generally Available: Deploy & manage long-running, stateful Agents', 'description': 'LangGraph Platform, our infrastructure for deploying and managing agents at scale, is now generally available. Learn how to deploy', 'language': 'en'}, page_content='LangGraph Platform is now Generally Available: Deploy & manage long-running, stateful Agents\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCase Studies\\n\\n\\n\\n\\nIn the Loop\\n\\n\\n\\n\\nLangChain\\n\\n\\n\\n\\nDocs\\n\\n\\n\\n\\nChangelog\\n\\n\\n\\n\\n\\nSign in\\nSubscribe\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLangGraph Platform is now Generally Available: Deploy & manage long-running, stateful Agents\\nLangGraph Platform, our infrastructure for deploying and managing agents at scale, is now generally available. Learn how to deploy\\n\\n4 min read\\nMay 14, 2025'), Document(id='1d592445-3560-4033-8ccb-301b4753e5cb', metadata={'source': 'https://blog.langchain.dev/langgraph-platform-ga/', 'title': 'LangGraph Platform is now Generally Available: Deploy & manage long-running, stateful Agents', 'description': 'LangGraph Platform, our infrastructure for deploying and managing agents at scale, is now generally available. Learn how to deploy', 'language': 'en'}, page_content=\"Today we’re excited to announce the general availability of LangGraph Platform — our purpose-built infrastructure and management layer for deploying and scaling long-running, stateful agents. Since our beta last June, nearly 400 companies have used LangGraph Platform to deploy their agents into production.\\xa0Agent deployment is the next hard hurdle for shipping reliable agents, and LangGraph Platform dramatically lowers this barrier with:1-click deployment to go live in minutes,\\xa030 API endpoints for designing custom user experiences that fit any interaction patternHorizontal scaling to handle bursty, long-running trafficA persistence layer to support memory, conversational history, and async collaboration with human-in-the-loop or multi-agent workflowsNative LangGraph Studio, the agent IDE, for easy debugging, visibility, and iterationRead on to learn more about what LangGraph Platform offers and which deployment option is right for you. If you're more of a visual learner, you can check out our video walkthrough here.The challenges of agent infrastructure – and how LangGraph Platform can helpOur team has the privilege of working with many of the most exciting companies building agents –\\xa0 such as Klarna, Lovable, Replit, Clay, LinkedIn. Through close collaboration, we’ve come to believe that the challenges of running agents, at scale, in production are often unique relative to traditional apps:Many agents are long running. Like we’ve seen with deep research agents, agents that run in the background on a schedule or in response to environment triggers can take a long time to return a final output. These workflows can be prone to failures mid-task, so they need durable infrastructure to ensure task completion.Many agents rely on async collaboration. Agents need to act on inputs from unpredictable events, whether collaborating with a human to steer / approve an action or waiting on another agent. For example – will the human reply immediately, tomorrow, or not at all? Good infrastructure accounts for this chaos and preserves state throughout.Bursty. While not totally unique to agents, horizontally scaling infra to handle traffic spikes is challenging –\\xa0 especially for tasks that run daily or on schedules.\\xa0We want engineers to obsess over building the best agent architecture – not worry about infra. LangGraph Platform’s server suits these kinds of workloads at scale. Developers can just 1-click deploy their apps directly in the management console to get started.1-click deploy with our native GitHub integration —\\xa0just select a repo, and ship! Accelerate agent development with visual workflowsBuilding great agents requires fast feedback loops. LangGraph Studio (included as part of LangGraph Platform) helps developers visualize and debug agent workflows in real time, with detailed visibility into agent trajectories and support for branching logic and retries.\\xa0You can also test edge cases, inspect memory/state at each step, and quickly pinpoint where things go wrong. Instead of retrying things from scratch, built-in checkpointing and memory modules in LangGraph Platform make it easy to rewind, edit, and rerun failure points without frustration.Whether you’re using our pre-built agent templates for common agent workflows, or building from scratch, LangGraph Platform lets you scaffold your agentic apps quickly – going from an idea to production in hours.\\xa0Centralize agent management across your orgAs agents get adopted across teams, managing them becomes a team sport. LangGraph Platform gives organizations a unified view of every agent in development or production — helping fellow team members iterate and scale across use cases. The enterprise tier also supports RBAC and workspaces, so that you can control access and sharing.The LangGraph Platform management console makes it easier to enforce consistency, monitor behavior, and ship updates safely — all without needing to re-deploy or touch code every time. You can:Discover available agents\"), Document(id='cb8460a1-efe3-424f-885a-f14733ef914e', metadata={'source': 'https://blog.langchain.dev/langgraph-platform-ga/', 'title': 'LangGraph Platform is now Generally Available: Deploy & manage long-running, stateful Agents', 'description': 'LangGraph Platform, our infrastructure for deploying and managing agents at scale, is now generally available. Learn how to deploy', 'language': 'en'}, page_content='Join our newsletter\\nUpdates from the LangChain team and community\\n\\n\\nEnter your email\\n\\nSubscribe\\n\\nProcessing your application...\\nSuccess! Please check your inbox and click the link to confirm your subscription.\\nSorry, something went wrong. Please try again.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSign up\\n\\n\\n\\n\\n\\n            © LangChain Blog 2025')], 'answer': 'LangGraph Platform is designed specifically for deploying and managing long-running, stateful agents.  You can use it in several ways, depending on your needs and technical capabilities:\\n\\n\\n**1.  Direct Deployment:**  The easiest way is via 1-click deployment from the management console, using a native GitHub integration.  You select your repository, and LangGraph handles the rest.  This accelerates agent development.\\n\\n**2. API Integration:** For more customized workflows, LangGraph provides 30 API endpoints to design user experiences tailored to your interaction patterns.  This gives you fine-grained control over the deployment and management of your agents.\\n\\n**3. LangGraph Studio:** This built-in IDE helps you visualize and debug agent workflows in real time.  You can monitor agent trajectories, handle branching logic and retries, inspect memory/state, and easily identify and fix issues.  This visual approach makes development and troubleshooting much more efficient.\\n\\n**4.  Pre-built Templates:**  LangGraph offers pre-built agent templates for common workflows, allowing for faster prototyping and deployment.\\n\\n**5. Multi-Agent Architectures:** LangGraph allows you to leverage other agents as \"Remote Graphs,\" enabling the creation of distributed, multi-agent systems.\\n\\n\\nThe platform offers various deployment options: Cloud (SaaS), Hybrid (SaaS control plane with self-hosted data plane), and Fully Self-Hosted.  The choice depends on your data sensitivity and infrastructure preferences.  There\\'s even a free Developer plan for testing and hobbyist projects.\\n\\nIn short, LangGraph provides a comprehensive infrastructure and management layer for building, deploying, and scaling your agents, handling the complexities of long-running tasks, asynchronous collaboration, and bursty traffic.'}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ddc882c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangGraph Platform is designed specifically for deploying and managing long-running, stateful agents.  You can use it in several ways, depending on your needs and technical capabilities:\n",
      "\n",
      "\n",
      "**1.  Direct Deployment:**  The easiest way is via 1-click deployment from the management console, using a native GitHub integration.  You select your repository, and LangGraph handles the rest.  This accelerates agent development.\n",
      "\n",
      "**2. API Integration:** For more customized workflows, LangGraph provides 30 API endpoints to design user experiences tailored to your interaction patterns.  This gives you fine-grained control over the deployment and management of your agents.\n",
      "\n",
      "**3. LangGraph Studio:** This built-in IDE helps you visualize and debug agent workflows in real time.  You can monitor agent trajectories, handle branching logic and retries, inspect memory/state, and easily identify and fix issues.  This visual approach makes development and troubleshooting much more efficient.\n",
      "\n",
      "**4.  Pre-built Templates:**  LangGraph offers pre-built agent templates for common workflows, allowing for faster prototyping and deployment.\n",
      "\n",
      "**5. Multi-Agent Architectures:** LangGraph allows you to leverage other agents as \"Remote Graphs,\" enabling the creation of distributed, multi-agent systems.\n",
      "\n",
      "\n",
      "The platform offers various deployment options: Cloud (SaaS), Hybrid (SaaS control plane with self-hosted data plane), and Fully Self-Hosted.  The choice depends on your data sensitivity and infrastructure preferences.  There's even a free Developer plan for testing and hobbyist projects.\n",
      "\n",
      "In short, LangGraph provides a comprehensive infrastructure and management layer for building, deploying, and scaling your agents, handling the complexities of long-running tasks, asynchronous collaboration, and bursty traffic.\n"
     ]
    }
   ],
   "source": [
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3a5123",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
