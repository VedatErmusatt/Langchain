{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cd04412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b5029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42cc41ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6ea5e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Ankara' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []} id='run--2c48624b-2d6c-4130-aa0e-d937152f87ad-0' usage_metadata={'input_tokens': 7, 'output_tokens': 2, 'total_tokens': 9, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "text= \"What is the capital of Turkey?\"\n",
    "print(llm.invoke(text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53aa63e",
   "metadata": {},
   "source": [
    "- LLM'ler metin çıktısı verir, chat modeller message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec66fbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Tell me a joke about {topic}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86b1e06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Tell me a joke about cats.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(topic=\"cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e9a6d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fa836f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why are cats such bad dancers? \\n\\nBecause they have two left feet... and two more left feet!', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run--9db0d23c-8475-4cb8-803f-7ae77bdf7ebd-0', usage_metadata={'input_tokens': 7, 'output_tokens': 23, 'total_tokens': 30, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\":\"cats\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b71b90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ai mesajını metine dönüştürmek için\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "789cab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6bd3ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why was the cat sitting on the computer?  To keep an eye on the mouse!\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"topic\": \"cats\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e66619d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğer prompt templatesi mesaj listesi üretmek için kullanılabilir. Böylece prompt hem content hakkında bilgiyi içerir hem de mesajın rolü de ayarlanabilir. Bunun için: ChatPromptTemplate\n",
    "\n",
    "template = \"Your are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "\n",
    "human_templates = \"{text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e78e43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", template),\n",
    "        (\"human\", human_templates)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81951fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Your are a helpful assistant that translates English to Turkish.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hello, how are you?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt.format_messages(\n",
    "    input_language=\"English\",\n",
    "    output_language=\"Turkish\",\n",
    "    text=\"Hello, how are you?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e948c70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Merhaba, nasılsınız?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = chat_prompt | llm | output_parser\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"Turkish\",\n",
    "        \"text\": \"Hello, how are you?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9019e6",
   "metadata": {},
   "source": [
    "## Chainlerle Çalışma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bffd0b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} joke about {content}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a70fa4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Tell me a funny joke about cats.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.format(\n",
    "    adjective=\"funny\",\n",
    "    content=\"cats\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc7f89cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chainleri deklaretif olarak oluşturmak için | operatörünü kullanabiliriz.\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c6f735b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Crowd-pleasing & relatively easy:**  Slow-cooked pulled pork shoulder with coleslaw and brioche buns.  It's impressive, flavorful, and can be largely prepped ahead of time, leaving you free to enjoy your guests.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"Give me a suggestion for the main course of a dinner party.\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e183552",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Tell me a short joke about {topic}.\"\n",
    ")\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b1c6f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7825b600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why are cats such bad dancers? \n",
      "\n",
      "Because they have two left feet!\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"topic\": \"cats\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85497111",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"You are an English-Turkish translator that return whatever the user says in Turkish.\"),\n",
    "    (\"user\", \"{input}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4defe258",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f9dd68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Olmak ya da olmamak!'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "        \"input\": \"To be or not to be!\"\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
