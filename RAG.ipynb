{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdaa165e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "229298e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e699396",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9cb039e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f8d438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14fda00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain's LangGraph is a powerful tool for building and managing complex applications leveraging large language models (LLMs).  It's not a single, monolithic component but rather a framework and methodology for structuring LLM-based applications as directed acyclic graphs (DAGs).  This allows for intricate workflows involving multiple LLMs, external data sources, and other processing steps, all orchestrated and managed efficiently.\n",
      "\n",
      "Here's a breakdown of its key aspects:\n",
      "\n",
      "**Core Functionality:**\n",
      "\n",
      "* **DAG Representation:** LangGraph represents applications as DAGs.  Each node in the graph represents a specific processing step, such as calling an LLM, querying a database, or performing some other computation.  The edges define the dependencies between these steps, outlining the flow of data and control. This visual representation makes complex applications much easier to understand, debug, and maintain.\n",
      "\n",
      "* **Modular Design:**  The modular nature promotes reusability.  Individual nodes can be developed, tested, and deployed independently, then combined to create larger applications.  This simplifies development and allows for easier adaptation to changing requirements.\n",
      "\n",
      "* **LLM Orchestration:** LangGraph excels at managing interactions with multiple LLMs.  It allows you to select the most appropriate LLM for each task based on its strengths and weaknesses, leading to more efficient and effective applications.\n",
      "\n",
      "* **External Data Integration:**  LangGraph is not limited to LLMs. It seamlessly integrates with external data sources and other tools, enhancing the capabilities of your applications.  This could include databases, APIs, or custom-built components.\n",
      "\n",
      "* **Extensibility:**  LangGraph is designed to be extensible, allowing developers to add custom nodes and functionalities to tailor the framework to their specific needs.\n",
      "\n",
      "**Benefits of Using LangGraph:**\n",
      "\n",
      "* **Improved Complexity Management:**  Handling the complexity of large LLM-based applications becomes significantly easier with the visual and modular design.\n",
      "\n",
      "* **Enhanced Reusability:**  Modular components can be reused across multiple applications, reducing development time and effort.\n",
      "\n",
      "* **Increased Efficiency:**  Choosing the right LLM for each task optimizes performance and cost.\n",
      "\n",
      "* **Better Maintainability:**  The structured approach makes applications easier to understand, debug, and maintain over time.\n",
      "\n",
      "* **Scalability:**  The DAG structure allows for relatively straightforward scaling of applications as needed.\n",
      "\n",
      "**In Summary:**\n",
      "\n",
      "LangGraph is not a standalone tool but a powerful framework for structuring and managing the complexity inherent in building advanced applications with LLMs.  It provides a structured, modular, and visually intuitive approach to building applications that go beyond simple LLM prompts, enabling sophisticated workflows and integrations.  While details of its implementation might vary, the core concept of DAG-based orchestration remains central to its design and benefits.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(input=\"What is Langgraph\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbbe2229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://blog.langchain.dev/langgraph-platform-ga/\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a625f09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://blog.langchain.dev/langgraph-platform-ga/', 'title': 'LangGraph Platform is now Generally Available: Deploy & manage long-running, stateful Agents', 'description': 'LangGraph Platform, our infrastructure for deploying and managing agents at scale, is now generally available. Learn how to deploy', 'language': 'en'}, page_content='\\n\\n\\nLangGraph Platform is now Generally Available: Deploy & manage long-running, stateful Agents\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCase Studies\\n\\n\\n\\n\\nIn the Loop\\n\\n\\n\\n\\nLangChain\\n\\n\\n\\n\\nDocs\\n\\n\\n\\n\\nChangelog\\n\\n\\n\\n\\n\\nSign in\\nSubscribe\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLangGraph Platform is now Generally Available: Deploy & manage long-running, stateful Agents\\nLangGraph Platform, our infrastructure for deploying and managing agents at scale, is now generally available. Learn how to deploy\\n\\n4 min read\\nMay 14, 2025\\n\\n\\n\\n\\n\\nToday we’re excited to announce the general availability of LangGraph Platform — our purpose-built infrastructure and management layer for deploying and scaling long-running, stateful agents. Since our beta last June, nearly 400 companies have used LangGraph Platform to deploy their agents into production.\\xa0Agent deployment is the next hard hurdle for shipping reliable agents, and LangGraph Platform dramatically lowers this barrier with:1-click deployment to go live in minutes,\\xa030 API endpoints for designing custom user experiences that fit any interaction patternHorizontal scaling to handle bursty, long-running trafficA persistence layer to support memory, conversational history, and async collaboration with human-in-the-loop or multi-agent workflowsNative LangGraph Studio, the agent IDE, for easy debugging, visibility, and iterationRead on to learn more about what LangGraph Platform offers and which deployment option is right for you. If you\\'re more of a visual learner, you can check out our video walkthrough here.The challenges of agent infrastructure – and how LangGraph Platform can helpOur team has the privilege of working with many of the most exciting companies building agents –\\xa0 such as Klarna, Lovable, Replit, Clay, LinkedIn. Through close collaboration, we’ve come to believe that the challenges of running agents, at scale, in production are often unique relative to traditional apps:Many agents are long running. Like we’ve seen with deep research agents, agents that run in the background on a schedule or in response to environment triggers can take a long time to return a final output. These workflows can be prone to failures mid-task, so they need durable infrastructure to ensure task completion.Many agents rely on async collaboration. Agents need to act on inputs from unpredictable events, whether collaborating with a human to steer / approve an action or waiting on another agent. For example – will the human reply immediately, tomorrow, or not at all? Good infrastructure accounts for this chaos and preserves state throughout.Bursty. While not totally unique to agents, horizontally scaling infra to handle traffic spikes is challenging –\\xa0 especially for tasks that run daily or on schedules.\\xa0We want engineers to obsess over building the best agent architecture – not worry about infra. LangGraph Platform’s server suits these kinds of workloads at scale. Developers can just 1-click deploy their apps directly in the management console to get started.1-click deploy with our native GitHub integration —\\xa0just select a repo, and ship! Accelerate agent development with visual workflowsBuilding great agents requires fast feedback loops. LangGraph Studio (included as part of LangGraph Platform) helps developers visualize and debug agent workflows in real time, with detailed visibility into agent trajectories and support for branching logic and retries.\\xa0You can also test edge cases, inspect memory/state at each step, and quickly pinpoint where things go wrong. Instead of retrying things from scratch, built-in checkpointing and memory modules in LangGraph Platform make it easy to rewind, edit, and rerun failure points without frustration.Whether you’re using our pre-built agent templates for common agent workflows, or building from scratch, LangGraph Platform lets you scaffold your agentic apps quickly – going from an idea to production in hours.\\xa0Centralize agent management across your orgAs agents get adopted across teams, managing them becomes a team sport. LangGraph Platform gives organizations a unified view of every agent in development or production — helping fellow team members iterate and scale across use cases. The enterprise tier also supports RBAC and workspaces, so that you can control access and sharing.The LangGraph Platform management console makes it easier to enforce consistency, monitor behavior, and ship updates safely — all without needing to re-deploy or touch code every time. You can:Discover available agents in the agent registryCreate different versions of your agent (“assistants”) in LangGraph platform, allowing you to reuse common agent architectures\\xa0Leverage other agents as “Remote Graphs”, allowing you to create multi agent architectures that run in a distributed mannerFor companies like Qualtrics, centralizing agent management with LangGraph Platform has been critical to driving efficiency:\\xa0\"The future of agentic AI is multi-vendor and AI agents must be built in an ecosystem. By using LangGraph Platform to build and manage our AI agents - Experience Agents - Qualtrics is able to design, deploy, and manage complex generative AI agent workflows with efficiency, speed, and scale.\" – Phil McKennan, VP of Strategy and Partnerships at QualtricsTry LangGraph Platform todayLangGraph Platform reduces time to production and enables better application experiences with a runtime that suits the workload and improves DevEx with well crafted APIs, built-in memory, and a Studio development environment. Today, LangGraph Platform is generally available.\\xa0To get started, choose the deployment option that fits your team’s needs:\\xa0Cloud (SaaS): Fastest way to get started, fully managed and easy deployment from within LangSmith. Available on our Plus plan and Enterprise plan.\\xa0To get started, read the docs (Plus plan) or\\xa0contact sales (Enterprise).Hybrid: SaaS control plane with self-hosted data plane — ideal for teams with sensitive data but still want more of a managed service. Available only on the Enterprise plan.\\xa0To get started, contact salesFully Self-Hosted: Run the entire platform within your own infrastructure. No data leaves your VPC. Available on the Enterprise plan. To get started, contact sales.If you want to try out a basic version of our LangGraph server in your environment, you can also self-host on our Developer plan and get up to 100k nodes executed per month for free – great to give you exposure to LangGraph Platform and run hobbyist projects on your infra. To get started on the Developer tier, read the docs.Learn more about deployment options here and view pricing details.\\xa0LangGraph Platform is the easiest way to develop, deploy, and manage long-running, stateful agents. It can be used independently from LangChain’s other products – LangChain (integrations), LangGraph (agent orchestration), and LangSmith (Evals and Observability), or stack together to provide an easy transition from the build phase to production.To learn more, visit the LangGraph Platform webpage. We can’t wait to see how far you can run with your agents.\\xa0\\n\\n\\nJoin our newsletter\\nUpdates from the LangChain team and community\\n\\n\\nEnter your email\\n\\nSubscribe\\n\\nProcessing your application...\\nSuccess! Please check your inbox and click the link to confirm your subscription.\\nSorry, something went wrong. Please try again.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSign up\\n\\n\\n\\n\\n\\n            © LangChain Blog 2025\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5cb2ab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sayısal temsillere çevirip vektör veri tabanında(faiss) saklayalım\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "125da28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4db90ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f6ee983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://blog.langchain.dev/langgraph-platform-ga/', 'title': 'LangGraph Platform is now Generally Available: Deploy & manage long-running, stateful Agents', 'description': 'LangGraph Platform, our infrastructure for deploying and managing agents at scale, is now generally available. Learn how to deploy', 'language': 'en'}, page_content='LangGraph Platform is now Generally Available: Deploy & manage long-running, stateful Agents\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCase Studies\\n\\n\\n\\n\\nIn the Loop\\n\\n\\n\\n\\nLangChain\\n\\n\\n\\n\\nDocs\\n\\n\\n\\n\\nChangelog\\n\\n\\n\\n\\n\\nSign in\\nSubscribe\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLangGraph Platform is now Generally Available: Deploy & manage long-running, stateful Agents\\nLangGraph Platform, our infrastructure for deploying and managing agents at scale, is now generally available. Learn how to deploy\\n\\n4 min read\\nMay 14, 2025'),\n",
       " Document(metadata={'source': 'https://blog.langchain.dev/langgraph-platform-ga/', 'title': 'LangGraph Platform is now Generally Available: Deploy & manage long-running, stateful Agents', 'description': 'LangGraph Platform, our infrastructure for deploying and managing agents at scale, is now generally available. Learn how to deploy', 'language': 'en'}, page_content=\"Today we’re excited to announce the general availability of LangGraph Platform — our purpose-built infrastructure and management layer for deploying and scaling long-running, stateful agents. Since our beta last June, nearly 400 companies have used LangGraph Platform to deploy their agents into production.\\xa0Agent deployment is the next hard hurdle for shipping reliable agents, and LangGraph Platform dramatically lowers this barrier with:1-click deployment to go live in minutes,\\xa030 API endpoints for designing custom user experiences that fit any interaction patternHorizontal scaling to handle bursty, long-running trafficA persistence layer to support memory, conversational history, and async collaboration with human-in-the-loop or multi-agent workflowsNative LangGraph Studio, the agent IDE, for easy debugging, visibility, and iterationRead on to learn more about what LangGraph Platform offers and which deployment option is right for you. If you're more of a visual learner, you can check out our video walkthrough here.The challenges of agent infrastructure – and how LangGraph Platform can helpOur team has the privilege of working with many of the most exciting companies building agents –\\xa0 such as Klarna, Lovable, Replit, Clay, LinkedIn. Through close collaboration, we’ve come to believe that the challenges of running agents, at scale, in production are often unique relative to traditional apps:Many agents are long running. Like we’ve seen with deep research agents, agents that run in the background on a schedule or in response to environment triggers can take a long time to return a final output. These workflows can be prone to failures mid-task, so they need durable infrastructure to ensure task completion.Many agents rely on async collaboration. Agents need to act on inputs from unpredictable events, whether collaborating with a human to steer / approve an action or waiting on another agent. For example – will the human reply immediately, tomorrow, or not at all? Good infrastructure accounts for this chaos and preserves state throughout.Bursty. While not totally unique to agents, horizontally scaling infra to handle traffic spikes is challenging –\\xa0 especially for tasks that run daily or on schedules.\\xa0We want engineers to obsess over building the best agent architecture – not worry about infra. LangGraph Platform’s server suits these kinds of workloads at scale. Developers can just 1-click deploy their apps directly in the management console to get started.1-click deploy with our native GitHub integration —\\xa0just select a repo, and ship! Accelerate agent development with visual workflowsBuilding great agents requires fast feedback loops. LangGraph Studio (included as part of LangGraph Platform) helps developers visualize and debug agent workflows in real time, with detailed visibility into agent trajectories and support for branching logic and retries.\\xa0You can also test edge cases, inspect memory/state at each step, and quickly pinpoint where things go wrong. Instead of retrying things from scratch, built-in checkpointing and memory modules in LangGraph Platform make it easy to rewind, edit, and rerun failure points without frustration.Whether you’re using our pre-built agent templates for common agent workflows, or building from scratch, LangGraph Platform lets you scaffold your agentic apps quickly – going from an idea to production in hours.\\xa0Centralize agent management across your orgAs agents get adopted across teams, managing them becomes a team sport. LangGraph Platform gives organizations a unified view of every agent in development or production — helping fellow team members iterate and scale across use cases. The enterprise tier also supports RBAC and workspaces, so that you can control access and sharing.The LangGraph Platform management console makes it easier to enforce consistency, monitor behavior, and ship updates safely — all without needing to re-deploy or touch code every time. You can:Discover available agents\"),\n",
       " Document(metadata={'source': 'https://blog.langchain.dev/langgraph-platform-ga/', 'title': 'LangGraph Platform is now Generally Available: Deploy & manage long-running, stateful Agents', 'description': 'LangGraph Platform, our infrastructure for deploying and managing agents at scale, is now generally available. Learn how to deploy', 'language': 'en'}, page_content='management console makes it easier to enforce consistency, monitor behavior, and ship updates safely — all without needing to re-deploy or touch code every time. You can:Discover available agents in the agent registryCreate different versions of your agent (“assistants”) in LangGraph platform, allowing you to reuse common agent architectures\\xa0Leverage other agents as “Remote Graphs”, allowing you to create multi agent architectures that run in a distributed mannerFor companies like Qualtrics, centralizing agent management with LangGraph Platform has been critical to driving efficiency:\\xa0\"The future of agentic AI is multi-vendor and AI agents must be built in an ecosystem. By using LangGraph Platform to build and manage our AI agents - Experience Agents - Qualtrics is able to design, deploy, and manage complex generative AI agent workflows with efficiency, speed, and scale.\" – Phil McKennan, VP of Strategy and Partnerships at QualtricsTry LangGraph Platform todayLangGraph Platform reduces time to production and enables better application experiences with a runtime that suits the workload and improves DevEx with well crafted APIs, built-in memory, and a Studio development environment. Today, LangGraph Platform is generally available.\\xa0To get started, choose the deployment option that fits your team’s needs:\\xa0Cloud (SaaS): Fastest way to get started, fully managed and easy deployment from within LangSmith. Available on our Plus plan and Enterprise plan.\\xa0To get started, read the docs (Plus plan) or\\xa0contact sales (Enterprise).Hybrid: SaaS control plane with self-hosted data plane — ideal for teams with sensitive data but still want more of a managed service. Available only on the Enterprise plan.\\xa0To get started, contact salesFully Self-Hosted: Run the entire platform within your own infrastructure. No data leaves your VPC. Available on the Enterprise plan. To get started, contact sales.If you want to try out a basic version of our LangGraph server in your environment, you can also self-host on our Developer plan and get up to 100k nodes executed per month for free – great to give you exposure to LangGraph Platform and run hobbyist projects on your infra. To get started on the Developer tier, read the docs.Learn more about deployment options here and view pricing details.\\xa0LangGraph Platform is the easiest way to develop, deploy, and manage long-running, stateful agents. It can be used independently from LangChain’s other products – LangChain (integrations), LangGraph (agent orchestration), and LangSmith (Evals and Observability), or stack together to provide an easy transition from the build phase to production.To learn more, visit the LangGraph Platform webpage. We can’t wait to see how far you can run with your agents.'),\n",
       " Document(metadata={'source': 'https://blog.langchain.dev/langgraph-platform-ga/', 'title': 'LangGraph Platform is now Generally Available: Deploy & manage long-running, stateful Agents', 'description': 'LangGraph Platform, our infrastructure for deploying and managing agents at scale, is now generally available. Learn how to deploy', 'language': 'en'}, page_content='Join our newsletter\\nUpdates from the LangChain team and community\\n\\n\\nEnter your email\\n\\nSubscribe\\n\\nProcessing your application...\\nSuccess! Please check your inbox and click the link to confirm your subscription.\\nSorry, something went wrong. Please try again.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSign up\\n\\n\\n\\n\\n\\n            © LangChain Blog 2025')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a580c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d403b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bir retriever chain'i oluşturalım, bu chain gelen soruyu alacak daha sonra ilgili dökümanları bulacak ve bunları orijinal soruyla birlikte LLM'e verecek\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Answer the following question based only on the provided context: \n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "    Question: {input}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7b3a40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dokümanları modele geçirmek için zincir kur\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "document_chain = create_stuff_documents_chain(model, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a2f9e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4805ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector.as_retriever()\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f4d8742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided text, LangGraph is a platform for deploying and managing long-running, stateful agents at scale.  It includes a management console to enforce consistency, monitor behavior, and ship updates; a Studio development environment for debugging and iteration; and  supports various deployment options (cloud, hybrid, fully self-hosted).  It's designed to handle the unique challenges of agent infrastructure, such as long-running tasks, asynchronous collaboration, and bursty traffic.  LangGraph Platform is part of a larger suite of LangChain products, but can be used independently.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke(\n",
    "    {\n",
    "        \"input\":\"What is LangGraph\"\n",
    "    }\n",
    ")\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d41a4cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "my_doc = Document(\n",
    "    page_content=\" LangGraph is a platform for deploying and managing long-running, stateful agents at scale.  It includes a management console to enforce consistency, monitor behavior, and ship updates; a Studio development environment for debugging and iteration; and  supports various deployment options (cloud, hybrid, fully self-hosted).\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04f71f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangGraph is a platform for deploying and managing long-running, stateful agents at scale.  It includes a management console, a Studio development environment, and supports various deployment options (cloud, hybrid, fully self-hosted).'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_chain.invoke(\n",
    "    {\n",
    "        \"input\":\"What is LangGraph?\",\n",
    "        \"context\":[my_doc]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df38235e",
   "metadata": {},
   "source": [
    "Genelde LLM'ler sorulara doğru cevap tam olarak veremediği için bu tekniği kullanıyoruz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
